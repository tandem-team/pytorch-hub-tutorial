{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tandem-team/pytorch-hub-tutorial/blob/master/Instance_Segmentation_using_Mask_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkYMM78Tter2"
   },
   "source": [
    "#  <font style=\"color:blue\">Instance Segmentation using Mask RCNN</font>\n",
    "\n",
    "In this session, we will learn how to train instance segmentation model using detectron2's pretrained Mask RCNN model. First, lets understand instance segmentation. Instance segmentation task is the labelling of each foreground pixel with object and instance.\n",
    "\n",
    "**Instant Segmentation -> Object Detection + Semantic Segmentation**\n",
    "\n",
    "Instance Segmentation is challenging because it requires the correct detection of all objects in an image while also precisely segmenting each instance. It therefore combines elements from the classical computer vision tasks of object detection, where the goal is to classify individual objects and localize each using a bounding box, and semantic segmentation, where the goal is to classify each pixel into a fixed set of categories without differentiating object instances.\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w11-instance-egmentation.png\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoUOtsCeter8"
   },
   "source": [
    "#  <font style=\"color:green\">1. Model</font>\n",
    "\n",
    "Now, lets understand how Mask RCNN performs instance segmentation. **Mask RCNN** extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition.\n",
    "\n",
    "In brief, **Faster RCNN**  consists of two stages. The first stage, called a Region Proposal Network (RPN),\n",
    "proposes candidate object bounding boxes. The second stage, which is in essence Fast R-CNN, extracts features using RoIPool from each candidate box and performs classification and bounding-box regression. Mask R-CNN adopts the same two-stage procedure, with an identical first stage (which is RPN). In the second stage, in parallel to predicting the class and box offset, Mask R-CNN also outputs a binary mask for each RoI.\n",
    "\n",
    "Lets see how we can train custom object using detectron2 and pretrained Mask RCNN model. We will see how **backpacks** can be detected and segmented in videos using our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YOeTHhFter_"
   },
   "source": [
    "# <font style=\"color:green\">2. Dataset Ingestion</font>\n",
    "\n",
    "We will use OpenImages dataset to download backpack images, masks and their corresponding labels. The detectron2's standard dataset format is COCO format so here, we will show how to convert the OpenImages dataset to COCO format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP6DJ9w7tesA"
   },
   "source": [
    "## <font style=\"color:green\">2.1. Introduction to OpenImages</font>\n",
    "\n",
    "\n",
    "**[Go to OpenImages](https://storage.googleapis.com/openimages/web/index.html)**\n",
    "\n",
    "Google has introduced OpenImages, an open source dataset containing `~ 9 million` images annotated with labels spanning thousands of object categories. In `2018`, it has released OpenImages `V4` which included `15.4M` bounding-boxes for `600` object categories, making it the largest existing dataset with object location annotations, as well as over `300k` visual relationship annotations. Recently, it has released Open Images `V5`, which adds segmentation masks to the set of annotations.\n",
    "\n",
    "Open Images `V5` features segmentation masks for `2.8 million` object instances in `350` categories. Unlike bounding-boxes, which only identify regions in which an object is located, segmentation masks mark the outline of objects, characterizing their spatial extent to a much higher level of detail. Importantly, these masks cover a broader range of object categories and a larger total number of instances than any previous dataset.\n",
    "\n",
    "**For instance segmentation, COCO format will have json containing all the images, segmentations information. So, we will also show how this json can be created.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPdYPRONtesC"
   },
   "source": [
    "## <font style=\"color:green\">2.2. Download Mask Images</font>\n",
    "\n",
    "**There are two methods to prepare mask images:**\n",
    "\n",
    "- (a) Download the prepared mask images for the backpack class.\n",
    "\n",
    "\n",
    "- (b) Download the class description file, and all mask images then filter mask images for the backpack.\n",
    "\n",
    "Although the first method is the easiest one, however, it is recommended to go through the second method as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iQAmxdVtesD"
   },
   "source": [
    "### <font style=\"color:green\">2.2.a. Prepared Mask Images for Backpacks</font>\n",
    "\n",
    "**You can download prepared masks data from this [link](https://www.dropbox.com/s/uj57mbztvyg5tiq/backpack-masks.zip?dl=1) and unzip it.**\n",
    "\n",
    "\n",
    "**You can also download and unzip data by running cells.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hxg5T6WtesF"
   },
   "source": [
    "**Create the root directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "YRuqFfAptesH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# create a data root\n",
    "data_root = 'data'\n",
    "\n",
    "os.makedirs(data_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBzHuDXxtesJ"
   },
   "source": [
    "**Function to download using URL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hBE7VL6ltesM"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def download(url, filepath):\n",
    "    response = urllib.request.urlretrieve(url, filepath)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiEVd1vmtesN"
   },
   "source": [
    "**Let's declare download_unzip flag, make it true when we have to download the data else make it false.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1lCtXm-QtesO"
   },
   "outputs": [],
   "source": [
    "# make it true to download all required data\n",
    "download_unzip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "0HqWhL7ItesP"
   },
   "outputs": [],
   "source": [
    "mask_backpacks_url = 'https://www.dropbox.com/s/uj57mbztvyg5tiq/backpack-masks.zip?dl=1'\n",
    "mask_backpacks_zip_path = os.path.join(os.path.abspath(os.getcwd()), data_root, 'backpack_pack.zip')\n",
    "\n",
    "if download_unzip:\n",
    "    download(mask_backpacks_url, mask_backpacks_zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPJNFGHvtesQ"
   },
   "source": [
    "**Function for unzips a zip-file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "6vy7CjxftesR"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def unzip(zip_filepath, target_dir):\n",
    "    with zipfile.ZipFile(zip_filepath,'a') as zip_ref:\n",
    "        zip_ref.extractall(target_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "id": "1QtHORBctesR",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workroom\\smart_cow\\data\\backpack_pack.zip\n"
     ]
    },
    {
     "ename": "ReadError",
     "evalue": "C:\\workroom\\smart_cow\\data\\backpack_pack.zip is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0ea49f42b19b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdownload_unzip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0munzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_backpacks_zip_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackpacks_unzip_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-c37c8ea1abc6>\u001b[0m in \u001b[0;36munzip\u001b[1;34m(zip_filepath, target_dir)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0munzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_archive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#     with zipfile.ZipFile(zip_filepath,'a') as zip_ref:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#         zip_ref.extractall(target_dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mobis\\Anaconda3\\envs\\flying_saucer\\lib\\shutil.py\u001b[0m in \u001b[0;36munpack_archive\u001b[1;34m(filename, extract_dir, format)\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_UNPACK_FORMATS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_UNPACK_FORMATS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m         \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mobis\\Anaconda3\\envs\\flying_saucer\\lib\\shutil.py\u001b[0m in \u001b[0;36m_unpack_zipfile\u001b[1;34m(filename, extract_dir)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not a zip file\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[0mzip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mReadError\u001b[0m: C:\\workroom\\smart_cow\\data\\backpack_pack.zip is not a zip file"
     ]
    }
   ],
   "source": [
    "backpacks_unzip_path = os.path.join(data_root, \"ext_path\")\n",
    "\n",
    "if download_unzip:\n",
    "    unzip(mask_backpacks_zip_path, backpacks_unzip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roE6pGuStesR"
   },
   "source": [
    "### <font style=\"color:green\">2.2.b. Download and Filter</font>\n",
    "\n",
    "We have to download mask images for backpacks. First, we need to find whether the mask for **backpacks** is available or not. If it is available, what is its ClassId? To check this, we need to download `class-descriptions-segmentable.csv`.\n",
    "\n",
    "**[Download class-descriptions-segmentable.csv](https://www.dropbox.com/s/wtl8s3ofy45ezgl/class-descriptions-segmentable.csv?dl=1)**\n",
    "\n",
    "\n",
    "**You can also download by running the below cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2H4jOUartesS"
   },
   "outputs": [],
   "source": [
    "csv_url = 'https://www.dropbox.com/s/wtl8s3ofy45ezgl/class-descriptions-segmentable.csv?dl=1'\n",
    "class_descriptions_file_path = os.path.join(data_root, 'class-descriptions-segmentable.csv')\n",
    "\n",
    "if download_unzip:\n",
    "    download(csv_url, class_descriptions_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xAu3jQUtesS"
   },
   "source": [
    "**Let's find classId for backpacks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CTn2QGY5tesT"
   },
   "outputs": [],
   "source": [
    "def find_class_id(classname, csv_path='class-descriptions-segmentable.csv'):\n",
    "    with open(csv_path, 'r') as f:\n",
    "        for line in f:\n",
    "            clss = line.rstrip().split(\",\")\n",
    "\n",
    "            if clss[1] == classname:\n",
    "                return clss[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "collapsed": true,
    "id": "4t7mbE0DtesT",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f325b0e5-3a6d-423d-ae4f-0443c1638f8c"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-751595a3cd6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Backpack'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbackpack_class_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_class_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_descriptions_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Class ID of Backpack: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackpack_class_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-cc127df11ec6>\u001b[0m in \u001b[0;36mfind_class_id\u001b[1;34m(classname, csv_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mclss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mclss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclassname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mclss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "class_name = 'Backpack'\n",
    "\n",
    "backpack_class_id = find_class_id(class_name, class_descriptions_file_path)\n",
    "print('Class ID of Backpack: {}'.format(backpack_class_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wESo-zdtesV"
   },
   "source": [
    "From the above file, we can select any class of our choice and note the classid to get the images and masks belonging to the selected class. Here, the selected class **Backpack** classID is **`m01940j`**.\n",
    "\n",
    "We will download mask images from segmentation train image folders of **OpenImages V6**. Then collect the backpack masks from all the folders into single folder.\n",
    "\n",
    "#### Download Links\n",
    "https://storage.googleapis.com/openimages/v5/train-masks/train-masks-0.zip\n",
    "\n",
    "https://storage.googleapis.com/openimages/v5/train-masks/train-masks-1.zip\n",
    "\n",
    "https://storage.googleapis.com/openimages/v5/train-masks/train-masks-2.zip\n",
    "\n",
    "https://storage.googleapis.com/openimages/v5/train-masks/train-masks-3.zip\n",
    "\n",
    "\n",
    "We can download the raw mask data from the above links and unzip it.\n",
    "\n",
    "You can also download and unzip data by running the below code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DFDe0DCtesW"
   },
   "source": [
    "**Download `train-masks-*.zip` and `unzip` it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "huoa6DB9tesW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "data\\train-masks-0.zip\n",
      "File data\\train-masks-0.zip unzipped to data\\train-masks-0\n",
      "None\n",
      "data\\train-masks-1.zip\n",
      "File data\\train-masks-1.zip unzipped to data\\train-masks-1\n",
      "None\n",
      "data\\train-masks-2.zip\n",
      "File data\\train-masks-2.zip unzipped to data\\train-masks-2\n",
      "None\n",
      "data\\train-masks-3.zip\n",
      "File data\\train-masks-3.zip unzipped to data\\train-masks-3\n"
     ]
    }
   ],
   "source": [
    "mask_url = 'https://storage.googleapis.com/openimages/v5/train-masks/train-masks-{}.zip'\n",
    "mask_filepath = os.path.join(data_root, 'train-masks-{}.zip')\n",
    "\n",
    "unzip_path = os.path.join(data_root, 'train-masks-{}')\n",
    "\n",
    "if download_unzip:\n",
    "    for i in range(4):\n",
    "        res = download(mask_url.format(i), mask_filepath.format(i))\n",
    "        print(res)\n",
    "        unzip(mask_filepath.format(i), unzip_path.format(i))\n",
    "        print('File {} unzipped to {}'.format(mask_filepath.format(i), unzip_path.format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyYzwWXBtesX"
   },
   "source": [
    "#### Filter backpacks mask images\n",
    "\n",
    "We can also download more directories similar to the above. Once the mask folders are downloaded, lets select the backpack masks among all the mask folders and store it in a separate folder `backpack-masks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "TN2wummFtesX",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_mask_for_classid(classid, source_dir, target_dir):\n",
    "    \n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "        \n",
    "    for img_file in os.listdir(source_dir):\n",
    "        if classid in img_file:\n",
    "            file_path = os.path.join(source_dir, img_file)\n",
    "            shutil.copy(file_path, target_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7xnLMM1XtesY",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "backpack_mask_dir = os.path.join(data_root, 'backpack-masks')\n",
    "\n",
    "if download_unzip:\n",
    "    for i in range(4):\n",
    "        copy_mask_for_classid(backpack_class_id.replace('/', ''), unzip_path.format(i), backpack_mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuwz3JnltesY"
   },
   "source": [
    "## <font style=\"color:green\">2.3. Download Annotations File</font>\n",
    "\n",
    "We will have to download the annotation file for segmentation.\n",
    "\n",
    "**[Download the annotation file](https://storage.googleapis.com/openimages/v5/train-annotations-object-segmentation.csv).**\n",
    "\n",
    "You can also download by executing the below cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Lq-7fO7CtesZ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_seg_url = 'https://storage.googleapis.com/openimages/v5/train-annotations-object-segmentation.csv'\n",
    "train_seg_csv_path = os.path.join(data_root, 'train-annotations-object-segmentation.csv')\n",
    "\n",
    "if download_unzip:\n",
    "    download(train_seg_url, train_seg_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DvqbKv4tesZ"
   },
   "source": [
    "## <font style=\"color:green\">2.4. Download Images</font>\n",
    "\n",
    "We have to download only those images that have masks and annotations. \n",
    "\n",
    "The mask image files path are in the format of `imageID_classID_maskID.png`. Using the `imageIDs`, we will download the images using `s3`.\n",
    "\n",
    "**Let's write a function to get `imageId` form the mask filename.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "E7whXlf0tesa",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_imageid_from_masks(mask_dir_path):\n",
    "    \n",
    "    ids_list = os.listdir(mask_dir_path)\n",
    "    img_ids = []\n",
    "\n",
    "    for idl in ids_list:\n",
    "        t = idl.split(\"_\")[0]\n",
    "        img_ids.append(t)\n",
    "\n",
    "    return set(img_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KG_C252tesa"
   },
   "source": [
    "**Let's write a function to get class annotations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "G3CSZBGXtesb",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_class_annotations(classes_list, class_descriptions_csv, annotations_csv):\n",
    "    #list of selected classes\n",
    "    classes = classes_list\n",
    "\n",
    "    #Create dict with className to classId mapping\n",
    "    with open(class_descriptions_csv, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dict_list = {rows[1]:rows[0] for rows in reader}\n",
    "    \n",
    "    csvreader = open(annotations_csv, \"r\")\n",
    "    class_annotations = {}\n",
    "    \n",
    "    for ind in range(0, len(classes)):\n",
    "        class_name = classes[ind]\n",
    "        class_annotations[class_name] = []\n",
    "        print('Class {}: {}'.format(ind, class_name))\n",
    "\n",
    "        ##Select the annotations with backpack classID\n",
    "        for line in csvreader:\n",
    "            if dict_list[class_name] in line:\n",
    "                class_annotations[class_name].append(line.rstrip())\n",
    "                \n",
    "    return class_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_3p-Ejptesb"
   },
   "source": [
    "Now, we have a function to get image Ids and annotations. But we do not have images. Let's write a function to download images using image Ids and annotations.\n",
    "\n",
    "We have to download images from S3-bucket (AWS storage). Downloading files from s3 requires an AWS-CLI app or boto3 python package.  In the function, we will use the AWS-CLI app. \n",
    "\n",
    "### Check if AWS already Installed\n",
    "\n",
    "Run the following command in **`CLI`** to check if AWS already installed: \n",
    "```\n",
    "aws --version\n",
    "```\n",
    "Running this command should have the output similar to the following:\n",
    "```\n",
    "aws-cli/2.0.13 Python/3.7.3 Linux/5.3.0-51-generic botocore/2.0.0dev17\n",
    "```\n",
    "\n",
    "If not, you have to install AWS:\n",
    "\n",
    "- [Install AWS CLI MacOS](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html)\n",
    "\n",
    "\n",
    "- [Install AWS CLI Linux](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html)\n",
    "\n",
    "\n",
    "- [Install AWS CLI Windows](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "3_mAH6WWtesc",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def download_images_for_a_class(annotations, class_name, mask_dir_path, download_dir):\n",
    "    #Create directory for downloading images\n",
    "\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "        \n",
    "    class_annotations = annotations[class_name]\n",
    "    total_annotations = len(class_annotations)\n",
    "    image_id_set = get_imageid_from_masks(mask_dir_path)\n",
    "    print('Number of unique IDs: {}'.format(len(image_id_set)))\n",
    "\n",
    "    for line in class_annotations[0:total_annotations]:\n",
    "        line_parts = line.split(',')\n",
    "        image_id = line_parts[1]\n",
    "\n",
    "        if image_id not in image_id_set:\n",
    "            continue\n",
    "            \n",
    "        image_url = 's3://open-images-dataset/train/{}.jpg'.format(image_id)\n",
    "        # print(image_url)\n",
    "        download_path = os.path.join(download_dir, '{}.jpg'.format(image_id))\n",
    "        subprocess.run(['aws', 's3', '--no-sign-request', '--only-show-errors', 'cp', image_url, download_path])\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziwqLGM9tesc"
   },
   "source": [
    "From the `train-annotations-object-segmentation.csv`, all the backpack records are collected. These records are used for downloading the images using imageID from s3-bucket and also for grouping all the segmentation boxes belonging to the same image based on ImageID key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "At9iw2jktesc",
    "outputId": "dd42ed12-2ca2-4199-e097-8ed4dda22218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Backpack\n",
      "Total number of annotations: 1082\n"
     ]
    }
   ],
   "source": [
    "annotations = get_class_annotations(['Backpack'], class_descriptions_file_path, train_seg_csv_path)\n",
    "\n",
    "print('Total number of annotations: {}'.format(len(annotations['Backpack'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCe3vD3Jtesd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backpack_image_dir = os.path.join(data_root, 'backpack-images')\n",
    "\n",
    "if download_unzip:\n",
    "    download_images_for_a_class(annotations, 'Backpack', backpack_mask_dir, backpack_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ard_0DmAtesd"
   },
   "source": [
    "# <font style=\"color:green\">3. Data Preparation for Training</font>\n",
    "\n",
    "- We have a total of 329 training images. Data should be split into the train and validation set.\n",
    "\n",
    "\n",
    "- We need data in the COCO JSON format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZAuBGkdtese"
   },
   "source": [
    "## <font style=\"color:green\">3.1. Split Data into Train and Validation</font>\n",
    "\n",
    "**Let's write a function to split data into train and validation in a `9:1` ratio.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZH-lzDDtese"
   },
   "outputs": [],
   "source": [
    "def split_train_validation(data_dir_path):\n",
    "    \n",
    "    img_filenames = os.listdir(data_dir_path)\n",
    "    train = []\n",
    "    val = []\n",
    "    for i, img_file in enumerate(img_filenames):\n",
    "        if i%10 == 0:\n",
    "            val.append(img_file)\n",
    "        else:\n",
    "            train.append(img_file)\n",
    "            \n",
    "    print('Number of training samples: {}'.format(len(train)))\n",
    "    print('Number of validation samples: {}'.format(len(val)))\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZlk7qiDtese",
    "outputId": "98c33e6b-5efc-49e9-ede3-87e5dec8aea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 296\n",
      "Number of validation samples: 33\n"
     ]
    }
   ],
   "source": [
    "train_images, val_images = split_train_validation(backpack_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KidADnMAtesf"
   },
   "source": [
    "## <font style=\"color:green\">3.2. Generate COCO formatted JSON</font>\n",
    "\n",
    "**Sample of COCO JSON format:**\n",
    "\n",
    "```\n",
    "{\n",
    "    \"images\": {\"file_name\": imageID + \".jpg\",\n",
    "               \"height\": imageHeight,\n",
    "               \"width\": imageWidth,\n",
    "               \"id\": imageID\n",
    "              },\n",
    "    \"categories\": { \"supercategory\": \"object\",\n",
    "                    \"id\": classID,\n",
    "                    \"name\": className\n",
    "                  },\n",
    "    \"annotations\": { \"segmentation\": contourPts,\n",
    "                     \"iscrowd\": 0,\n",
    "                     \"image_id\": imageID,\n",
    "                     \"bbox\": bounding box coordinates(XYWH),\n",
    "                     \"category_id\": classID,\n",
    "                     \"id\": boxID\n",
    "                   }\n",
    "}\n",
    "```\n",
    "\n",
    "We will get `contourPts` form mask images and `bounding box coordinates(XYWH)` from annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oT14Tsf0tesf"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_all_annotations_for_each_image(annotations, mask_dir_path, class_name, class_index):\n",
    "    \n",
    "    class_annotations = annotations[class_name]\n",
    "    annotations_count = len(class_annotations)\n",
    "    image_id_set = get_imageid_from_masks(mask_dir_path)\n",
    "    \n",
    "    #OpenImages Annotation Format\n",
    "    #MaskPath,ImageID,LabelName,BoxID,BoxXMin,BoxXMax,BoxYMin,BoxYMax,PredictedIoU,Clicks\n",
    "\n",
    "    boxes = defaultdict(list)\n",
    "\n",
    "    for line in class_annotations[0:annotations_count]:\n",
    "        line_parts = line.split(',')\n",
    "\n",
    "        ##Select annotations from those images whose masks we have downloaded\n",
    "        if line_parts[1] not in image_id_set:\n",
    "            continue\n",
    "\n",
    "        mask_path = line_parts[0]\n",
    "        image_id = line_parts[1]\n",
    "\n",
    "        xmin = line_parts[4]\n",
    "        xmax = line_parts[5]\n",
    "        ymin = line_parts[6]\n",
    "        ymax = line_parts[7]\n",
    "        bbox_id = line_parts[3]\n",
    "\n",
    "        #store annotations per image based on imageID\n",
    "        \n",
    "        dic = {\n",
    "            'mask_path': mask_path,\n",
    "            'class': str(class_index),\n",
    "            'bbox': [xmin, xmax, ymin, ymax],\n",
    "            'box_id': bbox_id\n",
    "        }\n",
    "        \n",
    "        boxes[image_id].append(dic)\n",
    "        \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjZzNbuItesg"
   },
   "outputs": [],
   "source": [
    "backpack_boxes = get_all_annotations_for_each_image(annotations, backpack_mask_dir, 'Backpack', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7REPrkVotesg"
   },
   "source": [
    "### Contour Calculation\n",
    "\n",
    "`cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_TC89_L1)`\n",
    "\n",
    "`cv2.CHAIN_APPROX_TC89_L1` option provides only the dominant points of the contour instead of all the contour points when used other options.\n",
    "\n",
    "`contour.shape[1] = 1` ensures that we select only non hierarchical contours so that we get rid of multiple contours of the same instance.\n",
    "\n",
    "Read more about contour [here](https://docs.opencv.org/trunk/d4/d73/tutorial_py_contours_begin.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0A6bybatesg"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_contour_pts(mask_path, width, height):\n",
    "    \n",
    "    # 0 is used to read image in gray scale mode\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    \n",
    "    mask_img = cv2.resize(mask, (width, height), cv2.INTER_NEAREST)\n",
    "    ret, thresh = cv2.threshold(mask_img, 127, 255, 0)\n",
    "    orig_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n",
    "        \n",
    "    sorted_contours = []\n",
    "    cnt_area = []\n",
    "\n",
    "    for cnt in orig_contours:\n",
    "        if len(cnt.shape) == 3 and cnt.shape[1] == 1:\n",
    "            cnt_area.append(cv2.contourArea(cnt))\n",
    "            sorted_contours.append(cnt.reshape(-1).tolist())\n",
    "\n",
    "    contour = [p for p in sorted_contours if len(p) > 4]\n",
    "    area = [cnt_area[i] for i,p in enumerate(sorted_contours) if len(p) > 4]\n",
    "    \n",
    "    return (contour, area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Tn8x2Stesg"
   },
   "source": [
    "**Lets see how we used backpack train and validation set to generate `train.json` and `validation.json`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb1aBx4htesh"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def generate_COCO_formatted_json(boxes, mask_dir, image_dir, image_list, json_filepath):\n",
    "    annotations = []\n",
    "    images = []\n",
    "    categories = []\n",
    "\n",
    "    for img_id, img_meta_list in boxes.items():\n",
    "        \n",
    "        image_filename = '{}.jpg'.format(img_id)\n",
    "        \n",
    "        if image_filename not in image_list:\n",
    "            continue\n",
    "            \n",
    "        img_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        for index, img_meta in enumerate(img_meta_list):\n",
    "            class_id = img_meta[\"class\"]\n",
    "            xp1, xp2, yp1, yp2 = img_meta[\"bbox\"]\n",
    "            x1, x2, y1, y2 = float(xp1)*w, float(xp2)*w, float(yp1)*h, float(yp2)*h\n",
    "            \n",
    "            mask_path = os.path.join(mask_dir, img_meta[\"mask_path\"])\n",
    "\n",
    "            contour, area = get_contour_pts(mask_path, w, h)        \n",
    "\n",
    "            if not contour:\n",
    "                continue\n",
    "\n",
    "            bbox_coord = [int(x1), int(y1), int(x2) - int(x1), int(y2) - int(y1)]\n",
    "\n",
    "            annotations.append({\n",
    "                \"segmentation\": contour,\n",
    "                \"iscrowd\": 0,\n",
    "                \"image_id\": img_id,\n",
    "                \"bbox\": bbox_coord,\n",
    "                \"area\": area[0],\n",
    "                \"category_id\": class_id,\n",
    "                \"id\": img_meta[\"box_id\"]})\n",
    "\n",
    "\n",
    "        images.append({\"file_name\": img_id + \".jpg\",\n",
    "            \"height\": h,\n",
    "            \"width\": w,\n",
    "            \"id\": img_id})\n",
    "\n",
    "\n",
    "    categories.append({\"supercategory\": \"object\", \"id\": class_id, \"name\": \"backpack\"})\n",
    "\n",
    "\n",
    "    with open(json_filepath, \"w\") as f:\n",
    "        json.dump({\"images\": images, \"annotations\": annotations, \"categories\": categories}, f)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpHyGORdtesh"
   },
   "outputs": [],
   "source": [
    "train_json_path = os.path.join(data_root, 'train.json')\n",
    "validation_json_path = os.path.join(data_root, 'validation.json')\n",
    "\n",
    "# Get train.json in coco format\n",
    "\n",
    "generate_COCO_formatted_json(boxes=backpack_boxes, \n",
    "                             mask_dir=backpack_mask_dir, \n",
    "                             image_dir=backpack_image_dir, \n",
    "                             image_list=train_images, \n",
    "                             json_filepath=train_json_path)\n",
    "\n",
    "# Get validation.json in coco format\n",
    "\n",
    "generate_COCO_formatted_json(boxes=backpack_boxes, \n",
    "                             mask_dir=backpack_mask_dir, \n",
    "                             image_dir=backpack_image_dir, \n",
    "                             image_list=val_images, \n",
    "                             json_filepath=validation_json_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Instance_Segmentation_using_Mask_RCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
